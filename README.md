# Fine-tuning-meta-llma2-7b-chat-using-LoRa
Fine tuning meta llma2 on a single GPU (colab &amp;*kaggle).
